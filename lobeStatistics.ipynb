{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f5243ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import math\n",
    "from scipy.optimize import curve_fit\n",
    "from collections import deque, defaultdict\n",
    "from itertools import combinations\n",
    "import seaborn as sns\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74b2334d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connectivityExtractor(name):\n",
    "    file_path = 'Networks/Network_Vessels_' + name +'.mat'\n",
    "    matlab_data = scipy.io.loadmat(file_path)\n",
    "    # Extract the 'connectivity' field from the 'Data' structured array\n",
    "    data_structure = matlab_data['Data']\n",
    "    connectivity_raw = data_structure['connectivity'][0, 0]  # Access the data (adjust indexing if needed)\n",
    "    # Reshape or ensure it's a proper 2D array (if required)\n",
    "    connectivity_data = connectivity_raw.squeeze()\n",
    "    # Create a DataFrame from the connectivity data\n",
    "    connectivity_df = pd.DataFrame(connectivity_data, columns=['Parent', 'Daughter1', 'Daughter2', 'Daughter3'])\n",
    "    connectivity_df.replace(0, np.nan, inplace=True) #ensure all nonexistent vessels have NaN\n",
    "    connectivity_df.at[0,'Parent']=0 #make sure first vessel is 0 (purposefully removed in last step for ease)\n",
    "    # Save the DataFrame to inspect it\n",
    "    return connectivity_df\n",
    "\n",
    "def lengthExtractor(name):\n",
    "    file_path = 'Networks/Network_Vessels_' + name +'.mat'\n",
    "    matlab_data = scipy.io.loadmat(file_path)\n",
    "    # Extract the 'lengths' field from the 'Data' structured array\n",
    "    data_structure = matlab_data['Data']\n",
    "    length_raw = data_structure['lengths'][0, 0]  # Access the data (adjust indexing if needed)\n",
    "    # Reshape or ensure it's a proper 2D array (if required)\n",
    "    length_data = length_raw.squeeze()\n",
    "    # Create a DataFrame from the data\n",
    "    length_df = pd.DataFrame(length_data, columns=['Length'])\n",
    "    # Save the DataFrame to inspect it\n",
    "    return length_df\n",
    "\n",
    "def radiusExtractor(name):\n",
    "    file_path = 'Networks/Network_Vessels_' + name +'.mat'\n",
    "    matlab_data = scipy.io.loadmat(file_path)\n",
    "    # Extract the 'radius' field from the 'Data' structured array\n",
    "    data_structure = matlab_data['Data']\n",
    "    radius_raw = data_structure['rin'][0, 0]  # Access the data (adjust indexing if needed)\n",
    "    # Reshape or ensure it's a proper 2D array (if required)\n",
    "    radius_data = radius_raw.squeeze()\n",
    "    # Create a DataFrame from the data\n",
    "    radius_df = pd.DataFrame(radius_data, columns=['Radius'])\n",
    "    # Save the DataFrame to inspect it\n",
    "    return radius_df\n",
    "\n",
    "def volumeExtractor(name):\n",
    "    file_path = 'Networks/Network_Vessels_' + name + '.mat'\n",
    "    matlab_data = scipy.io.loadmat(file_path)\n",
    "    volume_raw = matlab_data['volumes']  # This is an x by 1 or 1D array\n",
    "    volume_data = volume_raw.squeeze()  # Converts to 1D array if it's still 2D with 1 column\n",
    "    volume_df = pd.DataFrame(volume_data, columns=['Volume'])\n",
    "    return volume_df\n",
    "\n",
    "def lRR(data):\n",
    "    lrr = np.empty((0,0))\n",
    "    for i in np.arange(data.shape[0]): #iterate over every vessel\n",
    "        length = data.iloc[i]['Length'] #pull the length value\n",
    "        radius = data.iloc[i]['Radius'] #retreive radius value\n",
    "        lrr_value = length/radius #calculate lrr\n",
    "        lrr = np.append(lrr,lrr_value) #append lrr value to total list\n",
    "    data['Length/Radius'] = lrr.tolist() #add list to table\n",
    "    return data\n",
    "\n",
    "def assignDepth(data):\n",
    "    tree = {} \n",
    "    for _, row in data.iterrows(): #iterate over every row\n",
    "        parent = row['Parent']\n",
    "        daughters = row[['Daughter1', 'Daughter2', 'Daughter3']].dropna().astype(int).tolist() #only select daughter values that exist\n",
    "        tree[parent] = daughters\n",
    "    # Step 2: BFS traversal to assign depths\n",
    "    depths = {}\n",
    "    queue = deque([(data['Parent'].iloc[0], 0)])  # Start from root (first parent)\n",
    "\n",
    "    while queue:\n",
    "        node, depth = queue.popleft()\n",
    "        depths[node] = depth\n",
    "        for child in tree.get(node, []):\n",
    "            if child not in depths:  # Avoid revisiting\n",
    "                queue.append((child, depth + 1))\n",
    "    data['Depth'] = data['Parent'].map(depths)\n",
    "    return data\n",
    "\n",
    "def lengthFromRoot(data):\n",
    "    tree = {}\n",
    "    length_dict = dict(zip(data['Parent'], data['Length']))  # Map each vessel (parent) to its length\n",
    "\n",
    "    for _, row in data.iterrows():\n",
    "        parent = row['Parent']\n",
    "        daughters = row[['Daughter1', 'Daughter2', 'Daughter3']].dropna().astype(int).tolist()\n",
    "        tree[parent] = daughters\n",
    "\n",
    "    # BFS traversal to calculate cumulative lengths\n",
    "    lengths = {}\n",
    "    root = data['Parent'].iloc[0]\n",
    "    queue = deque([(root, 0)])  # Start with cumulative length 0\n",
    "\n",
    "    while queue:\n",
    "        node, cum_length = queue.popleft()\n",
    "        lengths[node] = cum_length\n",
    "        for child in tree.get(node, []):\n",
    "            if child not in lengths:  # Avoid revisiting\n",
    "                additional_length = length_dict.get(child, 0)\n",
    "                queue.append((child, cum_length + additional_length))\n",
    "\n",
    "    data['LengthFromRoot'] = data['Parent'].map(lengths)\n",
    "    return data\n",
    "\n",
    "def nodesExtractor(name): #extracts nodes and their corresponding information\n",
    "    file_path = 'Networks/Network_Vessels_' + name +'.mat'\n",
    "    matlab_data = scipy.io.loadmat(file_path)\n",
    "    # Extract the 'nodes' field\n",
    "    data_structure = matlab_data['nodesC2']\n",
    "    # Reshape or ensure it's a proper 2D array (if required)\n",
    "    nodes_data = data_structure.squeeze()\n",
    "    # Create a DataFrame from the connectivity data\n",
    "    nodes_df = pd.DataFrame(nodes_data, columns=['NodeID', 'X', 'Y', 'Z', 'Degree'])\n",
    "    # Save the DataFrame to inspect it\n",
    "    return nodes_df\n",
    "\n",
    "def edgesExtractor(name): #extracts segments to create a dataframe of from and to nodes\n",
    "    file_path = 'Networks/Network_Vessels_' + name +'.mat'\n",
    "    matlab_data = scipy.io.loadmat(file_path)\n",
    "    # Extract the 'segments' field\n",
    "    data_structure = matlab_data['segments']\n",
    "    # Reshape or ensure it's a proper 2D array (if required)\n",
    "    edges_data = data_structure.squeeze()\n",
    "    # Create a DataFrame from the connectivity data\n",
    "    edge_df = pd.DataFrame(edges_data, columns=['Old', 'From', 'To'])\n",
    "    # Save the DataFrame to inspect it\n",
    "    return edge_df\n",
    "\n",
    "def mapIDExtractor(name):\n",
    "    file_path = 'Networks/Network_Vessels_' + name +'.mat'\n",
    "    matlab_data = scipy.io.loadmat(file_path)\n",
    "    # Extract the 'mapID' field from the 'Data' structured array\n",
    "    data_structure = matlab_data['Data']\n",
    "    map_raw = data_structure['mapIDs'][0, 0]  # Access the data (adjust indexing if needed)\n",
    "    # Reshape or ensure it's a proper 2D array (if required)\n",
    "    map_data = map_raw.squeeze()\n",
    "    # Create a DataFrame from the connectivity data\n",
    "    map_df = pd.DataFrame(map_data, columns=['New', 'Old'])\n",
    "    # Save the DataFrame to inspect it\n",
    "    return map_df\n",
    "\n",
    "def tortuosityCalculator(data,name):\n",
    "    nodes = nodesExtractor(name)\n",
    "    edges = edgesExtractor(name)\n",
    "    maps = mapIDExtractor(name)\n",
    "    tortuosity = np.empty((0,0))\n",
    "    for i in np.arange(data.shape[0]):\n",
    "        old_vesID = maps.iloc[i]['Old'] #find the old vessel ID\n",
    "        edge_row = edges.index.get_loc(edges[edges['Old'] == old_vesID].index[0])\n",
    "        node1 = edges.iloc[edge_row]['From'] #identify from node\n",
    "        node2 = edges.iloc[edge_row]['To'] #identify to node\n",
    "        node1_row = nodes.index.get_loc(nodes[nodes['NodeID'] == node1].index[0])\n",
    "        node2_row = nodes.index.get_loc(nodes[nodes['NodeID'] == node2].index[0])\n",
    "        node1_x = nodes.iloc[node1_row]['X'] #pull node 3d coordinate\n",
    "        node1_y = nodes.iloc[node1_row]['Y']\n",
    "        node1_z = nodes.iloc[node1_row]['Z']\n",
    "        node2_x = nodes.iloc[node2_row]['X']\n",
    "        node2_y = nodes.iloc[node2_row]['Y']\n",
    "        node2_z = nodes.iloc[node2_row]['Z']\n",
    "        euclid_dist = math.sqrt((node1_x - node2_x)**2 + (node1_y - node2_y)**2 + (node1_z - node2_z)**2) #calculate euclidean distance between from and to\n",
    "        length = data.iloc[i]['Length'] #pull length and convert to mm\n",
    "        ratio = length/euclid_dist #find tortuosity ratio\n",
    "        tortuosity = np.append(tortuosity,ratio)\n",
    "    data['Tortuosity'] = tortuosity.tolist() #add to table\n",
    "    return data\n",
    "\n",
    "def radiusFinder(data):\n",
    "    dv1r = np.empty((0,0))\n",
    "    dv2r = np.empty((0,0))\n",
    "    dv3r = np.empty((0,0))\n",
    "    for i in np.arange(data.shape[0]):# iterate over every row\n",
    "        dv1 = data.iloc[i]['Daughter1'] #pull radii values\n",
    "        dv2 = data.iloc[i]['Daughter2']\n",
    "        dv3 = data.iloc[i]['Daughter3']\n",
    "        if math.isnan(dv1): #if daughter vessel 1 doesn't exist, none of them do\n",
    "            dv1r = np.append(dv1r,np.nan)\n",
    "            dv2r = np.append(dv2r,np.nan)\n",
    "            dv3r = np.append(dv3r,np.nan)\n",
    "            continue\n",
    "        dv1r = np.append(dv1r,data.iloc[int(dv1)][2])\n",
    "        dv2r = np.append(dv2r,data.iloc[int(dv2)][2])\n",
    "        if math.isnan(dv3): #explicitly check whetehr dv3 exist\n",
    "            dv3r = np.append(dv3r,np.nan)\n",
    "            continue\n",
    "        dv3r = np.append(dv3r,data.iloc[int(dv3)][2])\n",
    "    data['DV1R'] = dv1r.tolist()\n",
    "    data['DV2R'] = dv2r.tolist()\n",
    "    data['DV3R'] = dv3r.tolist()\n",
    "    #select and reorder columns\n",
    "    data = data.loc[:,['Parent','Depth','Length','Radius','Volume', 'Length/Radius','LengthFromRoot','Tortuosity','Daughter1','DV1R','Daughter2','DV2R','Daughter3','DV3R']]\n",
    "    return data\n",
    "\n",
    "def alphaBeta(data):\n",
    "    alpha = np.empty((0,0))\n",
    "    beta = np.empty((0,0))\n",
    "    for i in np.arange(data.shape[0]):\n",
    "        if not math.isnan(data.iloc[i]['DV3R']): #check if trifurcation, if it is then don't calculate\n",
    "            alpha = np.append(alpha,np.nan)\n",
    "            beta = np.append(beta,np.nan)\n",
    "            continue\n",
    "        dv1r = data.iloc[i]['DV1R']\n",
    "        dv2r = data.iloc[i]['DV2R']\n",
    "        pv = data.iloc[i]['Radius']\n",
    "        if math.isnan(dv1r): #check if daughter vessels exist\n",
    "            alpha = np.append(alpha,np.nan)\n",
    "            beta = np.append(beta,np.nan)\n",
    "            continue\n",
    "        if dv1r>=dv2r: #case 1 of daughter vessels\n",
    "            alpha_value = dv1r/pv\n",
    "            beta_value = dv2r/pv\n",
    "        else: #case 2 of daughter vessels\n",
    "            alpha_value = dv2r/pv\n",
    "            beta_value = dv1r/pv\n",
    "        alpha = np.append(alpha,alpha_value)\n",
    "        beta = np.append(beta,beta_value)\n",
    "    data['Alpha'] = alpha.tolist() #add alpha and beta to total table\n",
    "    data['Beta'] = beta.tolist()\n",
    "    return data\n",
    "\n",
    "def xiFinder(data):\n",
    "    xi_values = np.empty((0,0))\n",
    "    error_values = np.empty((0,0))\n",
    "    for i in np.arange(data.shape[0]):\n",
    "        rp = data.iloc[i]['Radius']/1000 #pull all radii and convert to mm\n",
    "        rd1 = data.iloc[i]['DV1R']/1000\n",
    "        rd2 = data.iloc[i]['DV2R']/1000\n",
    "        rd3 = data.iloc[i]['DV3R']/1000\n",
    "        if not math.isnan(rd3): #don't calculate if trifucation\n",
    "            xi_values = np.append(xi_values,np.nan)\n",
    "            error_values = np.append(error_values,np.nan)\n",
    "            continue\n",
    "        if math.isnan(rd1): #don't calculate if no daughter vessels\n",
    "            xi_values = np.append(xi_values,np.nan)\n",
    "            error_values = np.append(error_values,np.nan)\n",
    "            continue\n",
    "        xi = 2.5\n",
    "        error = rp**xi - rd1**xi - rd2**xi\n",
    "        while abs(error) > 1e-3: #allow for error up to 10^-4\n",
    "            fun = rp**xi - rd1**xi - rd2**xi # solve at f(xi)\n",
    "            fun2 = (rp**xi)*math.log(rp) - (rd1**xi)*math.log(rd1) - (rd2**xi)*math.log(rd2) #solve at f'(xi)\n",
    "            xi = xi - fun/fun2 # new xi value\n",
    "            error = rp**xi - rd1**xi - rd2**xi #calculate new error\n",
    "        if xi > 4: #bound xi\n",
    "            xi = 4\n",
    "        if xi < 2:\n",
    "            xi = 2\n",
    "        error = rp**xi - rd1**xi - rd2**xi\n",
    "        xi_values = np.append(xi_values,xi)\n",
    "        error_values = np.append(error_values,error)\n",
    "    data['Xi'] = xi_values.tolist()#add xi to the table\n",
    "    #data['Error Newton'] = error_values.tolist()\n",
    "    return data\n",
    "\n",
    "def asymmetry(data):\n",
    "    asym = np.empty((0,0))\n",
    "    for i in np.arange(data.shape[0]):\n",
    "        if not math.isnan(data.iloc[i]['DV3R']): #don't calculate if trifucation\n",
    "            asym = np.append(asym,np.nan)\n",
    "            continue\n",
    "        dv1r = data.iloc[i]['DV1R'] #pull radii\n",
    "        dv2r = data.iloc[i]['DV2R']\n",
    "        if math.isnan(dv1r): #if no daughters, skip\n",
    "            asym = np.append(asym,np.nan)\n",
    "            continue\n",
    "        if dv1r>=dv2r: #case 1\n",
    "            asym_value = (dv2r/dv1r)**2\n",
    "        else: #case 2\n",
    "            asym_value = (dv1r/dv2r)**2\n",
    "        asym = np.append(asym,asym_value)\n",
    "    data['Gamma'] = asym.tolist() #add to table\n",
    "    return data\n",
    "\n",
    "def area(data):\n",
    "    area = np.empty((0,0))\n",
    "    for i in np.arange(data.shape[0]):\n",
    "        if not math.isnan(data.iloc[i]['DV3R']): #if trifucation, skip\n",
    "            area = np.append(area,np.nan)\n",
    "            continue\n",
    "        dv1r = data.iloc[i]['DV1R'] #pull necessary radii\n",
    "        dv2r = data.iloc[i]['DV2R']\n",
    "        pv = data.iloc[i]['Radius']\n",
    "        if math.isnan(dv1r): #if no daughters, skip\n",
    "            area = np.append(area,np.nan)\n",
    "            continue\n",
    "        area_value = (dv1r**2+dv2r**2)/(pv**2) #calculate eta\n",
    "        area = np.append(area,area_value)\n",
    "    data['Eta'] = area.tolist() #add to table\n",
    "    return data\n",
    "\n",
    "def angleExtractor(name):\n",
    "    file_path = 'Networks/Network_Vessels_' + name +'.mat'\n",
    "    matlab_data = scipy.io.loadmat(file_path)\n",
    "    # Extract the 'connectivity' field from the 'Data' structured array\n",
    "    angles = matlab_data['Angles']\n",
    "    headers = [str(h.item()) if isinstance(h,np.ndarray) else str(h) for h in angles[0]]\n",
    "    columns = [angles[1,i].squeeze() for i in range(len(headers))]\n",
    "    angled = pd.DataFrame(dict(zip(headers,columns)))\n",
    "    return angled\n",
    "\n",
    "def matchAngles(data,name):\n",
    "    angles = angleExtractor(name)\n",
    "    edges = edgesExtractor(name)\n",
    "    maps = mapIDExtractor(name)\n",
    "    newOldIDs = pd.merge(maps, edges, on='Old', how='left')\n",
    "    angleID = pd.merge(newOldIDs,angles,left_on='To',right_on='hubNode')\n",
    "    angleID.drop(['Old','From','To','hubNode'],axis=1,inplace=True)\n",
    "    #vesAngle = angleID.merge(data,left_on='New',right_on='Parent',how='left')\n",
    "    angled = data.merge(angleID,left_on='Parent',right_on='New',how='left')\n",
    "    angled = angled.drop(columns='New')\n",
    "    return angled\n",
    "\n",
    "def dataExtractor(name): #sequentially calls necessary functions to create full table\n",
    "    connectivity = connectivityExtractor(name)\n",
    "    length = lengthExtractor(name)\n",
    "    radius = radiusExtractor(name)\n",
    "    volume = volumeExtractor(name)\n",
    "    combined = pd.concat([connectivity.iloc[:, :1], length, radius, volume, connectivity.iloc[:, 1:]], axis=1)\n",
    "    lengthradius = lRR(combined)\n",
    "    #print('LRR')\n",
    "    depthness = assignDepth(lengthradius)\n",
    "    #print('Depth')\n",
    "    lengthTotal = lengthFromRoot(depthness)\n",
    "    #print('LengthFromRoot')\n",
    "    tortuos = tortuosityCalculator(lengthTotal,name)\n",
    "    #print('Tortousity')\n",
    "    allradii = radiusFinder(tortuos)\n",
    "    angled = matchAngles(allradii,name)\n",
    "    alphabetazed = alphaBeta(angled)\n",
    "    #print('Alpha/beta')\n",
    "    xi = xiFinder(alphabetazed)\n",
    "    #print('Xi')\n",
    "    asymmetric = asymmetry(xi)\n",
    "    #print('Gamma')\n",
    "    areated = area(asymmetric)\n",
    "    return areated\n",
    "\n",
    "def findInputVessel(segments,fromnode,to):\n",
    "    vessel = segments[((segments['From'] == fromnode)&(segments['To']==to))|((segments['From'] == to)&(segments['To']==fromnode))]\n",
    "    return int(vessel['ID'])\n",
    "\n",
    "def lobeExtractor(name, vesID):\n",
    "    data = connectivityExtractor(name)\n",
    "    \n",
    "    tree = defaultdict(list)\n",
    "    for _,row in data.iterrows():\n",
    "        parent = row['Parent']\n",
    "        for daughter_col in ['Daughter1','Daughter2','Daughter3']:\n",
    "            daughter = row[daughter_col]\n",
    "            if pd.notna(daughter):\n",
    "                tree[parent].append(daughter)\n",
    "\n",
    "    visited = set()\n",
    "    queue = deque([vesID])\n",
    "\n",
    "    while queue:\n",
    "        current = queue.popleft()\n",
    "        if current not in visited:\n",
    "            visited.add(current)\n",
    "            queue.extend(tree.get(current,[]))\n",
    "    \n",
    "    visited.discard(vesID)  # Remove vesID from visited\n",
    "    downstream_df = data[data['Parent'].isin(visited)]\n",
    "    return downstream_df\n",
    "\n",
    "def lobeInput(name,fromnode,tonode):\n",
    "    segments = edgesExtractor(name)\n",
    "    maps = mapIDExtractor(name)\n",
    "    newOldIDs = pd.merge(maps, segments, on='Old', how='left')\n",
    "    newVesID = int(newOldIDs[((newOldIDs['From'] == fromnode)&(newOldIDs['To']==tonode))].iloc[0,0])\n",
    "    lobe = lobeExtractor(name,newVesID)\n",
    "    return lobe\n",
    "\n",
    "def lobeStatistics(name, fromnode,tonode):\n",
    "    data = dataExtractor(name)\n",
    "    lobe = lobeInput(name, fromnode,tonode)\n",
    "    filtered_data = data[data['Parent'].isin(lobe['Parent'])].reset_index(drop=True)\n",
    "    return filtered_data\n",
    "\n",
    "def saveLobeStatistics(name,fromnode,tonode,lobe):\n",
    "    data = lobeStatistics(name,fromnode,tonode)\n",
    "    file_path = 'Statistics/Statistics_' + name+ '_'+lobe+'.csv'\n",
    "    data.to_csv(file_path)\n",
    "\n",
    "def saveLobeStatisticsTwoIn(name,fromnode1,tonode1,fromnode2,tonode2,lobe):\n",
    "    data = lobeStatistics(name,fromnode1,tonode1)\n",
    "    data2 = lobeStatistics(name,fromnode2,tonode2)\n",
    "    datamerged = pd.concat([data,data2])\n",
    "    file_path = 'Statistics/Statistics_' + name+ '_'+lobe+'.csv'\n",
    "    datamerged.to_csv(file_path)\n",
    "\n",
    "def saveStatistics(name): #saves the stats as .csv for exporting\n",
    "    statistics = dataExtractor(name)\n",
    "    file_path = 'Statistics/Statistics_' + name +'.csv'\n",
    "    statistics.to_csv(file_path) #shouldn't return anything, just save\n",
    "\n",
    "def leaveDetails(statistics,name):\n",
    "    #statistics = dataExtractor(name)\n",
    "    dropped = statistics.dropna(subset='DV1R')\n",
    "    internal = dropped.shape[0]\n",
    "    tris = dropped['DV3R'].count()\n",
    "    leaves = statistics['DV1R'].isna().sum()\n",
    "    triratio = tris/internal * 100\n",
    "    avgdepth = statistics[statistics['Daughter1'].isna()]['Depth'].mean()\n",
    "    stddepth = statistics[statistics['Daughter1'].isna()]['Depth'].std()\n",
    "    volume = statistics['Volume'].sum()/(1000**3)\n",
    "    print(name)\n",
    "    print('# of vessels: ' + str(statistics.shape[0]))\n",
    "    print('# of leaves (terminal vessels): ' + str(leaves))\n",
    "    print('# of internal vessels: ' + str(internal))\n",
    "    print('# of trifurcations: '+ str(tris))\n",
    "    print('% of trifurcations: ' + str(round(triratio,3)))\n",
    "    print('Volume (mm^3): ' + str(round(volume,3)))\n",
    "    print('Average Depth of terminal vessel: ' + str(round(avgdepth,3)))\n",
    "    print('St. Dev. Depth of terminal vessel: ' + str(round(stddepth,3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b55c223",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'm1p4_053007'\n",
    "fromnode=1819\n",
    "tonode = 1818\n",
    "lobe = 'left' #must be a string\n",
    "saveLobeStatistics(name,fromnode,tonode,lobe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e14af5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "395"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = 'm1p1_053107'\n",
    "fromnode=4179\n",
    "tonode = 4304\n",
    "lobeStatistics(name,fromnode,tonode).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5d88bc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "995"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = 'm1p1_053107'\n",
    "fromnode=3954\n",
    "tonode = 3900\n",
    "lobeStatistics(name,fromnode,tonode).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8b544f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
